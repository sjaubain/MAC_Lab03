{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labo 3: Spark\n",
    "\n",
    "Authors: Christopher MEIER and Guillaume HOCHET\n",
    "\n",
    "Based on the work of: Gary MARIGLIANO and Miguel SANTAMARIA\n",
    "\n",
    "For MAC course given by Nastaran FATEMI\n",
    "\n",
    "Date: November 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.4`\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a spark session\n",
    "// To have better integration with Jupyter, we use a wrapper class provided by almond-spark\n",
    "import org.apache.spark.sql._\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    "}\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Retrieve the Spark context\n",
    "def sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case class Movie(id: Int, title: String, genres: Seq[String],\n",
    "                 description: String, director: String, actors: Seq[String],\n",
    "                 year: Int, rating: Float, votes: Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def parseRow(row: Row): Movie = {\n",
    "    val id = row.getInt(0)\n",
    "    val title = row.getString(1)\n",
    "    val genres = row.getString(2).split(\",\").toList\n",
    "    val description = row.getString(3)\n",
    "    val director = row.getString(4)\n",
    "    val actors = row.getString(5).split(\",\").toList\n",
    "    val year = row.getInt(6)\n",
    "    val rating = row.getDouble(8).toFloat\n",
    "    val votes = row.getInt(9)\n",
    "\n",
    "    Movie(id, title, genres, description, director, actors, year, rating, votes)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val filename = \"../data/IMDB-Movie-Data.csv\"\n",
    "val moviesDF = spark.read.format(\"csv\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .load(filename)\n",
    "val rddMovies = moviesDF.rdd.map(parseRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Print the title of the first 10 movies to see if they were correctly added.\n",
    "rddMovies.take(10).map(m => m.title).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Playing with the movies using RDD functions\n",
    "\n",
    "The goal of this part is to play (i.e. query, filter and transform the data) with the movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex1 - Print the movies whose title contains \"City\" \n",
    "\n",
    "Goal: \n",
    "\n",
    "* use `map()` and `filter()` methods to get the title of the movies that contains \"City\" in their title\n",
    " \n",
    "Output example:\n",
    "\n",
    "```plain\n",
    "City of Tiny Lights\n",
    "The Mortal Instruments: City of Bones\n",
    "```\n",
    "\n",
    "Steps:\n",
    "\n",
    "* Use `filter()` to only keep the movies that contains \"City\" in their title\n",
    "* Use `map()` to retrieve the titles of these filtered movies\n",
    "* Use `foreach()` to pretty print the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO students\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex2- Print the title of the movies rated between `rateMin` and `rateMax`. Take the 10 worst ratings.\n",
    "\n",
    "Goal:\n",
    "    \n",
    "* Take the titles of the movies that were rated between `rateMin` and `rateMax` (exclusing `rateMin` and including`rateMax`).\n",
    "* This list is sorted by rating ASC\n",
    "    \n",
    "Output example:\n",
    "\n",
    "```plain\n",
    "...\n",
    "3.5 - Wrecker\n",
    "3.7 - The Last Face\n",
    "...\n",
    "```\n",
    "    \n",
    "Steps:\n",
    "\n",
    "* Use `filter()` to only keep the movies released between `rateMin` and `rateMax`\n",
    "* Sort the filtered movies by decreasing rating\n",
    "* Use `map()` to keep only the relevant attributes (i.e. rating and title)\n",
    "* Use `foreach()` to pretty print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex3 - Print the 10 top genres\n",
    "\n",
    "Goals:\n",
    "\n",
    "* Print the list of the genres that appears the most\n",
    "* Use `flatMap()`\n",
    "\n",
    "Output example:\n",
    "\n",
    "```plain\n",
    "Drama (513)\n",
    "Action (303)\n",
    "Comedy (279)\n",
    "Adventure (259)\n",
    "```\n",
    "\n",
    "Theory:\n",
    "\n",
    "When an operation is giving you a sequence of sequences like:\n",
    "\n",
    "```scala\n",
    "Array(\"hello\", \"world\").map(word => word.split(\"\"))\n",
    "res91: Array[Array[String]] = Array(Array(h, e, l, l, o), Array(w, o, r, l, d))\n",
    "```\n",
    "\n",
    "You may want to flatten this to only have a single list like:\n",
    "```scala\n",
    "Array(\"hello\", \"world\").map(_.split(\"\")).flatten\n",
    "res93: Array[String] = Array(h, e, l, l, o, w, o, r, l, d)\n",
    "```\n",
    "\n",
    "You can achieve the same result (i.e. `map` + `flatten`) using `flatMap`:\n",
    "```scala\n",
    "Array(\"hello\", \"world\").flatMap(_.split(\"\"))\n",
    "res95: Array[String] = Array(h, e, l, l, o, w, o, r, l, d)\n",
    "```\n",
    "\n",
    "We are going to apply this same technique with the `genres` member.\n",
    "\n",
    "Steps:\n",
    "\n",
    "* Use `flatMap()` to get the list with all the genres\n",
    "* Make sure to remove trailling whitespaces\n",
    "* Count the genres\n",
    "* Sort them by decreasing order\n",
    "* Show the top N genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex4 - Print the average number of votes per year, order by descreasing number of votes\n",
    "\n",
    "Goal:\n",
    "\n",
    "* Print the average votes per year\n",
    "* This output is sorted by descreasing votes\n",
    "\n",
    "Output example:\n",
    "\n",
    "```plain\n",
    "...\n",
    "year: 2008 average votes: 275505.3846153846\n",
    "year: 2009 average votes: 255780.64705882352\n",
    "year: 2010 average votes: 252782.31666666668\n",
    "...\n",
    "```\n",
    "\n",
    "Theory:\n",
    "\n",
    "We are going to use `reduceByKey()` which has the following signature `reduceByKey(func: (V, V) => V): RDD[(K, V)]`. \n",
    "\n",
    "`reduceByKey()` works on a RDD like `RDD[(K,V)]` (i.e. sort of \"list of key/values pairs\"). \n",
    "\n",
    "`reduceByKey()` takes a function that, from two elements, returns one i.e. the `func: (V, V) => V` in the signature.\n",
    "The difference with `reduce()` is that `reduceByKey()` uses two elements sharing the same key.\n",
    "\n",
    "For example (pseudo code):\n",
    "\n",
    "```plain\n",
    " year, count\n",
    "(2010, 2)\n",
    "(2011, 3)\n",
    "(2011, 4)\n",
    "(2010, 8)\n",
    "// use reduceByKey((count1, count2) => count1+count2)\n",
    "> (2010, 10)\n",
    "> (2011, 7)\n",
    "```\n",
    "\n",
    "Note: here `count` is just an Int but it can be anything e.g. `Movie`\n",
    "\n",
    "Steps:\n",
    "\n",
    "* To compute the average we need the **total sum** of votes per year and the **count** of all the movies per year\n",
    "* Use `map()` to create an RDD made of `(year, (votes, 1))`. Like a word count we use the `1` to be able to count the number of movies per year\n",
    "* Use `reduceByKey()` to sum the votes and to count the number of movies per year. The output should look like: `(year, (totalVotes, moviePerYearCount))`\n",
    "* Find a way to compute the average using the result from the last operation\n",
    "* Sort by number of votes decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Create a basic Inverted Index\n",
    "\n",
    "The goal of this part is to show you how to create an inverted index that indexes words from all the movies' description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal:\n",
    "\n",
    "Using `rddMovies` create an inverted that use the movies' description:\n",
    "\n",
    "```plain\n",
    "Movie(1,Guardians of the Galaxy,List(Action, Adventure, Sci-Fi),A group of intergalactic [...] of the universe.,James Gunn,List(Chris Pratt, Vin Diesel, Bradley Cooper, Zoe Saldana),2014,8.1,757074.0)\n",
    "Movie(2,Prometheus,List(Adventure, Mystery, Sci-Fi),Following clues to the origin[...] not alone.,Ridley Scott,List(Noomi Rapace, Logan Marshall-Green, Michael Fassbender, Charlize Theron),2012,7.0,485820.0)\n",
    "Movie(3,Split,List(Horror, Thriller),Three girls are kidnapped [...] a frightful new 24th.,M. Night Shyamalan,List(James McAvoy, Anya Taylor-Joy, Haley Lu Richardson, Jessica Sula),2016,7.3,157606.0)\n",
    "...\n",
    "```\n",
    "\n",
    "and extract them to produce an inverted index like:\n",
    "\n",
    "```plain\n",
    "\"reunion\" -> (640, 697)\n",
    "\"runner\" -> (338)\n",
    "\"vietnam\" -> (797, 947, 983)\n",
    "...\n",
    "```\n",
    "\n",
    "Steps\n",
    "\n",
    "* Tokenize description i.e. produce an RDD like (movId, words)\n",
    "* Normalize words e.g. toLowercase, trimming,..\n",
    "* Remove stopwords (ignored here)\n",
    "* Apply stemming (ignored here)\n",
    "* Group by document id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(console):55:28 expected (If | While | Try | DoWhile | For | Throw | Return | ImplicitLambda | SmallerExprOrLambda)\n",
      "       val invertedIndex = ...\n",
      "                           ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "(console):55:28 expected (If | While | Try | DoWhile | For | Throw | Return | ImplicitLambda | SmallerExprOrLambda)\n       val invertedIndex = ...\n                           ^"
     ]
    }
   ],
   "source": [
    "    /**\n",
    "    * Goal: create an inverted index that allows searching a word\n",
    "    * in the movies description.\n",
    "    * Features:\n",
    "    * - case insensitive\n",
    "    *\n",
    "    */\n",
    "    // TODO student\n",
    "    // In this first function we are going to tokenize and order the descriptions of the movies, then return these data. We are not going to apply any search right now.\n",
    "    def createInvertedIndex(movies: RDD[Movie]): RDD[(String, Iterable[Int])] = {\n",
    "        // Define helper functions directly inside this function. In scala you can declare inner functions\n",
    "        // and use them only inside the function they were declared. Useful to encapsulate/restrict \n",
    "        // their use outside this function.\n",
    "        \n",
    "        // Split the given string into an array of words (without any formatting), then return it.\n",
    "        def tokenizeDescription(description: String): Seq[String] = {\n",
    "            // TODO student\n",
    "        }\n",
    "        \n",
    "        // Remove the blank spaces (trim) in the given word, transform it in lowercase, then return it.\n",
    "        def normalizeWord(word: String): String = {\n",
    "            // TODO student\n",
    "        }\n",
    "        \n",
    "        // For the sake of simplicity let's ignore the implementation (in a real case we would return true if w is a stopword, otherwise false).\n",
    "        // TODO student nothing here but still call this function in your invertedIndex creation process.\n",
    "        def isStopWord(w: String): Boolean = {\n",
    "          false\n",
    "        }\n",
    "        \n",
    "        // For the sake of simplicity let's ignore the implementation (in a real case we would apply stemming to w and return the result, e.g. w=automation -> w=automat).\n",
    "        // TODO student nothing here but still call this function in your invertedIndex creation process.\n",
    "        def applyStemming(w: String): String = {\n",
    "          w\n",
    "        }\n",
    "      \n",
    "       // TODO student\n",
    "       // Here we are going to work on the movies RDD, by tokenizing and normalizing the description of every movie, then by building a key-value object that contains the tokens as keys, and the IDs of the movies as values\n",
    "       // (see the example on 4).\n",
    "       // The goal here is to do everything by chaining the possible transformations and actions of Spark.\n",
    "       // Possible steps:\n",
    "       //   1) What we first want to do here is applying the 4 previous methods on any movie's description. Be aware of the fact that we also want to keep the IDs of the movies.\n",
    "       //   2) For each tokenized word, create a tuple as (word, id), where id is the current movie id\n",
    "       //        [\n",
    "       //          (\"toto\", 120), (\"mange\", 120), (\"des\", 120), (\"pommes\", 120),\n",
    "       //          (\"toto\", 121), (\"lance\", 121), (\"des\", 121), (\"photocopies\", 121)\n",
    "       //        ]\n",
    "       //      Hint: you can use a `map` function inside another `map` function.\n",
    "       //   3) We finally need to find a way to remove duplicated keys and thus only having one entry per key, with all the linked IDs as values. For example:\n",
    "       //        [\n",
    "       //          (\"toto\", [120, 121]),\n",
    "       //          (\"mange\", [120]),\n",
    "       //          ...\n",
    "       //        ]\n",
    "       val invertedIndex = ...\n",
    "\n",
    "       // Return the new-built inverted index.\n",
    "       invertedIndex\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to use our inverted index to display the top N most used words in the descriptions of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(console):8:19 expected (If | While | Try | DoWhile | For | Throw | Return | ImplicitLambda | SmallerExprOrLambda)\n",
      "  val topMovies = ...\n",
      "                  ^"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "(console):8:19 expected (If | While | Try | DoWhile | For | Throw | Return | ImplicitLambda | SmallerExprOrLambda)\n  val topMovies = ...\n                  ^"
     ]
    }
   ],
   "source": [
    "// TODO student\n",
    "// Here we are going to operate the analytic and display its result on a given inverted index (that will be obtained from the previous function).\n",
    "def topN(invertedIndex: RDD[(String, Iterable[Int])], N: Int): Unit = {\n",
    "  // TODO student\n",
    "  // We are going to work on the given invertedIndex array to do our analytic:\n",
    "  //   1) Find a way to get the number of movie in which a word appears.\n",
    "  //   2) Keep only the top N words and their occurence.\n",
    "  val topMovies = ...\n",
    "  \n",
    "  // Print the words and the number of descriptions in which they appear.\n",
    "  println(\"Top '\" + N + \"' most used words\")\n",
    "  topMovies.foreach(println)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd0.sc:1: not found: value createInvertedIndex\n",
      "val invertedIndex = createInvertedIndex(rddMovies)\n",
      "                    ^cmd0.sc:1: not found: value rddMovies\n",
      "val invertedIndex = createInvertedIndex(rddMovies)\n",
      "                                        ^cmd0.sc:7: not found: value topN\n",
      "val res0_2 = topN(invertedIndex, 10)\n",
      "             ^Compilation Failed"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "// Code used to test your implementation.\n",
    "// Create the inverted index of the movies.\n",
    "val invertedIndex = createInvertedIndex(rddMovies)\n",
    "\n",
    "// Show how the inverted index looks like.\n",
    "invertedIndex.take(3).foreach(x => println(x._1 + \": \" + x._2.mkString(\", \")))\n",
    "\n",
    "// Show the top 10 most used words.\n",
    "topN(invertedIndex, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Dataframe and SparkSQL\n",
    "\n",
    "For all of the following exercices, write your queries in two different ways: \n",
    "\n",
    "* using the sql literal \n",
    "* using DataFrame API (select, where, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1 - Use the moviesDF DataFrame\n",
    "\n",
    "* Use the dataframe `moviesDF` already created when loading the data \n",
    "* Print the schema of moviesDF\n",
    "* Show the first 10 lines of the moviesDF as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2 - Get the movies (id, title, votes, director) whose title contains \"City\" \n",
    "\n",
    "Apply two different ways: \n",
    "\n",
    "* use the sql literal \n",
    "* use DataFrame API (select, where, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3 - Get the number of movies which have a number of votes between 500 and 2000 (inclusive range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4 - Get the minimum, maximum and average rating of films per director. Sort the results by minimum rating.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5 - Find the title of the movie(s) having the minimum rating for each year. Show the title, year and the rating information in the result, order by increasing rating.\n",
    "\n",
    "**Example output**\n",
    "\n",
    "```plain\n",
    "+--------------------+----+------+\n",
    "|               title|year|rating|\n",
    "+--------------------+----+------+\n",
    "|      Disaster Movie|2008|   1.9|\n",
    "|Don't Fuck in the...|2016|   2.7|\n",
    "|Dragonball Evolution|2009|   2.7|\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 6 - Find the title of movies having the same director. \n",
    "\n",
    "**Example output**\n",
    "\n",
    "```plain\n",
    "+------------------+--------------------+--------------------+\n",
    "|         director1|              title1|              title2|\n",
    "+------------------+--------------------+--------------------+\n",
    "|        James Gunn|Guardians of the ...|               Super|\n",
    "|        James Gunn|Guardians of the ...|             Slither|\n",
    "|      Ridley Scott|          Prometheus|        Body of Lies|\n",
    "|      Ridley Scott|          Prometheus|         A Good Year|\n",
    "...\n",
    "```\n",
    "\n",
    "Note that when using the dataframe API:\n",
    "* You can use `===` to test equality of columns and `!==` to test non-equality of them\n",
    "* You can use the `as` keyword to make alias of column names and table names (check the reference documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.1",
    "jupytext_version": "1.2.4"
   }
  },
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
